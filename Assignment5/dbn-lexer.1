#reader(lib"read.ss""wxme")WXME0108 ## 
#|
   This file uses the GRacket editor format.
   Open this file in DrRacket version 7.4 or later to read it.

   Most likely, it was created by saving a program in DrRacket,
   and it probably contains a program with non-text elements
   (such as images or comment boxes).

            http://racket-lang.org/
|#
 33 7 #"wxtext\0"
3 1 6 #"wxtab\0"
1 1 8 #"wximage\0"
2 0 8 #"wxmedia\0"
4 1 34 #"(lib \"syntax-browser.ss\" \"mrlib\")\0"
1 0 36 #"(lib \"cache-image-snip.ss\" \"mrlib\")\0"
1 0 68
(
 #"((lib \"image-core.ss\" \"mrlib\") (lib \"image-core-wxme.rkt\" \"mr"
 #"lib\"))\0"
) 1 0 16 #"drscheme:number\0"
3 0 44 #"(lib \"number-snip.ss\" \"drscheme\" \"private\")\0"
1 0 36 #"(lib \"comment-snip.ss\" \"framework\")\0"
1 0 93
(
 #"((lib \"collapsed-snipclass.ss\" \"framework\") (lib \"collapsed-sni"
 #"pclass-wxme.ss\" \"framework\"))\0"
) 0 0 43 #"(lib \"collapsed-snipclass.ss\" \"framework\")\0"
0 0 19 #"drscheme:sexp-snip\0"
0 0 29 #"drscheme:bindings-snipclass%\0"
1 0 101
(
 #"((lib \"ellipsis-snip.rkt\" \"drracket\" \"private\") (lib \"ellipsi"
 #"s-snip-wxme.rkt\" \"drracket\" \"private\"))\0"
) 2 0 88
(
 #"((lib \"pict-snip.rkt\" \"drracket\" \"private\") (lib \"pict-snip.r"
 #"kt\" \"drracket\" \"private\"))\0"
) 0 0 55
#"((lib \"snip.rkt\" \"pict\") (lib \"snip-wxme.rkt\" \"pict\"))\0"
1 0 34 #"(lib \"bullet-snip.rkt\" \"browser\")\0"
0 0 25 #"(lib \"matrix.ss\" \"htdp\")\0"
1 0 22 #"drscheme:lambda-snip%\0"
1 0 29 #"drclickable-string-snipclass\0"
0 0 26 #"drracket:spacer-snipclass\0"
0 0 57
#"(lib \"hrule-snip.rkt\" \"macro-debugger\" \"syntax-browser\")\0"
1 0 26 #"drscheme:pict-value-snip%\0"
0 0 45 #"(lib \"image-snipr.ss\" \"slideshow\" \"private\")\0"
1 0 38 #"(lib \"pict-snipclass.ss\" \"slideshow\")\0"
2 0 55 #"(lib \"vertical-separator-snip.ss\" \"stepper\" \"private\")\0"
1 0 18 #"drscheme:xml-snip\0"
1 0 31 #"(lib \"xml-snipclass.ss\" \"xml\")\0"
1 0 21 #"drscheme:scheme-snip\0"
2 0 34 #"(lib \"scheme-snipclass.ss\" \"xml\")\0"
1 0 10 #"text-box%\0"
1 0 32 #"(lib \"text-snipclass.ss\" \"xml\")\0"
1 0 1 6 #"wxloc\0"
          0 0 58 0 1 #"\0"
0 75 1 #"\0"
0 10 90 -1 90 -1 3 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 255 255 255 1 -1 0 9
#"Standard\0"
0 75 12 #"Courier New\0"
0 10 90 -1 90 -1 3 -1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 255 255 255 1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 -1 -1 2 24
#"framework:default-color\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1 1 1 150 0 150 0 0 0 -1 -1 2 15
#"text:ports out\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 150 0 150 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1.0 0 -1 -1 93 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 255 0 0 0 0 0 -1
-1 2 15 #"text:ports err\0"
0 -1 1 #"\0"
1 0 -1 -1 93 -1 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 175 0 0 0 -1 -1 2 17
#"text:ports value\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 175 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1.0 0 92 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 34 139 34 0 0 0 -1
-1 2 27 #"Matching Parenthesis Style\0"
0 -1 1 #"\0"
1.0 0 92 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 34 139 34 0 0 0 -1
-1 2 1 #"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 38 38 128 0 0 0 -1 -1 2 37
#"framework:syntax-color:scheme:symbol\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 38 38 128 0 0 0 -1 -1 2 38
#"framework:syntax-color:scheme:keyword\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 38 38 128 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 194 116 31 0 0 0 -1 -1 2
38 #"framework:syntax-color:scheme:comment\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 194 116 31 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 41 128 38 0 0 0 -1 -1 2 37
#"framework:syntax-color:scheme:string\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 41 128 38 0 0 0 -1 -1 2 35
#"framework:syntax-color:scheme:text\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 41 128 38 0 0 0 -1 -1 2 39
#"framework:syntax-color:scheme:constant\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 41 128 38 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 132 60 36 0 0 0 -1 -1 2 49
#"framework:syntax-color:scheme:hash-colon-keyword\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 132 60 36 0 0 0 -1 -1 2 42
#"framework:syntax-color:scheme:parenthesis\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 132 60 36 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 36
#"framework:syntax-color:scheme:error\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 36
#"framework:syntax-color:scheme:other\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 16
#"Misspelled Text\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 81 112 203 0 0 0 -1 -1 2
38 #"drracket:check-syntax:lexically-bound\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 81 112 203 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 178 34 34 0 0 0 -1 -1 2 28
#"drracket:check-syntax:set!d\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 178 34 34 0 0 0 -1 -1 2 37
#"drracket:check-syntax:unused-require\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 36
#"drracket:check-syntax:free-variable\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 255 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 68 0 203 0 0 0 -1 -1 2 31
#"drracket:check-syntax:imported\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 68 0 203 0 0 0 -1 -1 2 47
#"drracket:check-syntax:my-obligation-style-pref\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 178 34 34 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 116 0 0 0 0 -1 -1 2 50
#"drracket:check-syntax:their-obligation-style-pref\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 116 0 0 0 0 -1 -1 2 48
#"drracket:check-syntax:unk-obligation-style-pref\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 139 142 28 0 0 0 -1 -1 2
49 #"drracket:check-syntax:both-obligation-style-pref\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 139 142 28 0 0 0 -1 -1 2
26 #"plt:htdp:test-coverage-on\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 1
#"\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 1 0 0 0 0 0 0 255 165 0 0 0 0 -1 -1 2 27
#"plt:htdp:test-coverage-off\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 1 0 0 0 0 0 0 255 165 0 0 0 0 -1 -1 4 1
#"\0"
0 70 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 1.0 1.0 1.0 1.0 1.0 1.0 0 0 0 0 0 0
-1 -1 4 4 #"XML\0"
0 70 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 1.0 1.0 1.0 1.0 1.0 1.0 0 0 0 0 0 0
-1 -1 2 37 #"plt:module-language:test-coverage-on\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 -1 -1 2 38
#"plt:module-language:test-coverage-off\0"
0 -1 1 #"\0"
1 0 -1 -1 -1 93 -1 -1 0 1 0 0 0 1 0 0 0 0 0 0 255 165 0 0 0 0 -1 -1 4 1
#"\0"
0 71 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 1.0 1.0 1.0 1.0 1.0 1.0 0 0 0 0 0 0
-1 -1 4 1 #"\0"
0 -1 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 1 0 0 0 0 0 0 0 0 1.0 1.0 1.0 0 0 255 0 0 0 -1
-1 4 1 #"\0"
0 71 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 1 0 0 0 0 0 0 0 0 1.0 1.0 1.0 0 0 255 0 0 0 -1
-1 4 1 #"\0"
0 71 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 0 100 0 0 0 0 -1
-1 4 1 #"\0"
0 71 1 #"\0"
1.0 0 -1 -1 93 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 255 0 0 0 0 0 -1
-1 2 1 #"\0"
0 70 1 #"\0"
1.0 0 -1 -1 93 -1 -1 -1 0 0 0 0 0 0 0 0 0 1.0 1.0 1.0 148 0 211 0 0 0 -1
-1 2 1 #"\0"
0 70 1 #"\0"
1.0 0 -1 -1 -1 -1 -1 -1 1 0 0 0 0 0 0 0 0 1.0 1.0 1.0 0 0 255 0 0 0 -1
-1           0 959 0 28 3 12 #"#lang racket"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 26 #"; needed for parsing stuff"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 7 #"require"
0 0 24 3 1 #" "
0 0 14 3 16 #"parser-tools/lex"
0 0 24 29 1 #"\n"
0 0 24 3 9 #"         "
0 0 24 29 1 #"\n"
0 0 24 3 9 #"         "
0 0 17 3 72
(
 #"; this last gives us prettier names for common regular expression st"
 #"uff,"
) 0 0 24 29 1 #"\n"
0 0 24 3 9 #"         "
0 0 17 3 69
(
 #"; and also renames it so they're all prefixed with ':' in their name"
 #"s"
) 0 0 24 29 1 #"\n"
0 0 24 3 10 #"         ("
0 0 14 3 9 #"prefix-in"
0 0 24 3 1 #" "
0 0 14 3 1 #":"
0 0 24 3 1 #" "
0 0 14 3 20 #"parser-tools/lex-sre"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 9 #"         "
0 0 19 3 16 #"\"dbn-errors.rkt\""
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 24 #"; just output everything"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 14 3 7 #"provide"
0 0 24 3 2 #" ("
0 0 14 3 15 #"all-defined-out"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 49 #"; now, define the tokens that the parser will use"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 13 #"define-tokens"
0 0 24 3 1 #" "
0 0 14 3 16 #"names-and-values"
0 0 24 3 2 #" ("
0 0 14 3 12 #"NUMERICVALUE"
0 0 24 29 1 #"\n"
0 0 24 3 33 #"                                 "
0 0 14 3 10 #"IDENTIFIER"
0 0 24 29 1 #"\n"
0 0 24 3 33 #"                                 "
0 0 14 3 7 #"FUNNAME"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 36 #"; this is for the end of file marker"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 19 #"define-empty-tokens"
0 0 24 3 1 #" "
0 0 14 3 11 #"end-of-file"
0 0 24 3 2 #" ("
0 0 14 3 3 #"EOF"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 28 #"; these are all the keywords"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 19 #"define-empty-tokens"
0 0 24 3 1 #" "
0 0 14 3 8 #"keywords"
0 0 24 3 2 #" ("
0 0 14 3 5 #"PAPER"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 3 #"PEN"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 4 #"LINE"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 3 #"SET"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 6 #"REPEAT"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 7 #"FOREVER"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 4 #"SAME"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 7 #"NOTSAME"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 7 #"SMALLER"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 10 #"NOTSMALLER"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 5 #"MOUSE"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 4 #"LOAD"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 6 #"NUMBER"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 5 #"VALUE"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 3 #"KEY"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 3 #"NET"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 4 #"TIME"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 5 #"PRINT"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 7 #"COMMAND"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 9 #"ANTIALIAS"
0 0 24 29 1 #"\n"
0 0 24 3 31 #"                               "
0 0 14 3 7 #"NEWLINE"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 30 #"; these are the math operators"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 19 #"define-empty-tokens"
0 0 24 3 1 #" "
0 0 14 3 14 #"math-operators"
0 0 24 3 2 #" ("
0 0 14 3 8 #"ADDITION"
0 0 24 29 1 #"\n"
0 0 24 3 37 #"                                     "
0 0 14 3 11 #"SUBTRACTION"
0 0 24 29 1 #"\n"
0 0 24 3 37 #"                                     "
0 0 14 3 14 #"MULTIPLICATION"
0 0 24 29 1 #"\n"
0 0 24 3 37 #"                                     "
0 0 14 3 8 #"DIVISION"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 38 #"; these are the parentheses variations"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 19 #"define-empty-tokens"
0 0 24 3 1 #" "
0 0 14 3 11 #"parentheses"
0 0 24 3 2 #" ("
0 0 14 3 15 #"LEFTPARENTHESIS"
0 0 24 29 1 #"\n"
0 0 24 3 34 #"                                  "
0 0 14 3 16 #"RIGHTPARENTHESIS"
0 0 24 29 1 #"\n"
0 0 24 3 34 #"                                  "
0 0 14 3 8 #"LESSTHAN"
0 0 24 29 1 #"\n"
0 0 24 3 34 #"                                  "
0 0 14 3 11 #"GREATERTHAN"
0 0 24 29 1 #"\n"
0 0 24 3 34 #"                                  "
0 0 14 3 9 #"LEFTBRACE"
0 0 24 29 1 #"\n"
0 0 24 3 34 #"                                  "
0 0 14 3 10 #"RIGHTBRACE"
0 0 24 29 1 #"\n"
0 0 24 3 34 #"                                  "
0 0 14 3 11 #"LEFTBRACKET"
0 0 24 29 1 #"\n"
0 0 24 3 34 #"                                  "
0 0 14 3 12 #"RIGHTBRACKET"
0 0 24 3 2 #"))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 73
(
 #"; and finally the lexer, this returns a function that takes an input"
 #" port"
) 0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 1 #" "
0 0 14 3 8 #"dbnlexer"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 14 3 13 #"lexer-src-pos"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\+"
0 0 24 3 46 #"                                             ("
0 0 14 3 14 #"token-ADDITION"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\-"
0 0 24 3 46 #"                                             ("
0 0 14 3 17 #"token-SUBTRACTION"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\*"
0 0 24 3 46 #"                                             ("
0 0 14 3 20 #"token-MULTIPLICATION"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\/"
0 0 24 3 46 #"                                             ("
0 0 14 3 14 #"token-DIVISION"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\("
0 0 24 3 46 #"                                             ("
0 0 14 3 21 #"token-LEFTPARENTHESIS"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\{"
0 0 24 3 46 #"                                             ("
0 0 14 3 15 #"token-LEFTBRACE"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\["
0 0 24 3 46 #"                                             ("
0 0 14 3 17 #"token-LEFTBRACKET"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\<"
0 0 24 3 46 #"                                             ("
0 0 14 3 14 #"token-LESSTHAN"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\)"
0 0 24 3 46 #"                                             ("
0 0 14 3 22 #"token-RIGHTPARENTHESIS"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\}"
0 0 24 3 46 #"                                             ("
0 0 14 3 16 #"token-RIGHTBRACE"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\]"
0 0 24 3 46 #"                                             ("
0 0 14 3 18 #"token-RIGHTBRACKET"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 21 3 3 #"#\\>"
0 0 24 3 46 #"                                             ("
0 0 14 3 17 #"token-GREATERTHAN"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 2 #":+"
0 0 24 3 1 #" "
0 0 21 3 9 #"#\\newline"
0 0 24 3 36 #")                                  ("
0 0 14 3 13 #"token-NEWLINE"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 38 #";;; TODO: add Paper, Pen, Line and Set"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 8 #"\"REPEAT\""
0 0 24 3 1 #" "
0 0 19 3 8 #"\"Repeat\""
0 0 24 3 27 #")                         ("
0 0 14 3 12 #"token-REPEAT"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 9 #"\"FOREVER\""
0 0 24 3 1 #" "
0 0 19 3 9 #"\"Forever\""
0 0 24 3 25 #")                       ("
0 0 14 3 13 #"token-FOREVER"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 7 #"\"SAME?\""
0 0 24 3 1 #" "
0 0 19 3 7 #"\"Same?\""
0 0 24 3 29 #")                           ("
0 0 14 3 10 #"token-SAME"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 10 #"\"NOTSAME?\""
0 0 24 3 1 #" "
0 0 19 3 10 #"\"Notsame?\""
0 0 24 3 1 #" "
0 0 19 3 10 #"\"NotSame?\""
0 0 24 3 12 #")          ("
0 0 14 3 13 #"token-NOTSAME"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 10 #"\"SMALLER?\""
0 0 24 3 1 #" "
0 0 19 3 10 #"\"Smaller?\""
0 0 24 3 23 #")                     ("
0 0 14 3 13 #"token-SMALLER"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 13 #"\"NOTSMALLER?\""
0 0 24 3 1 #" "
0 0 19 3 13 #"\"Notsmaller?\""
0 0 24 3 1 #" "
0 0 19 3 13 #"\"NotSmaller?\""
0 0 24 3 3 #") ("
0 0 14 3 16 #"token-NOTSMALLER"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 7 #"\"MOUSE\""
0 0 24 3 1 #" "
0 0 19 3 7 #"\"Mouse\""
0 0 24 3 29 #")                           ("
0 0 14 3 11 #"token-MOUSE"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 6 #"\"LOAD\""
0 0 24 3 1 #" "
0 0 19 3 6 #"\"Load\""
0 0 24 3 31 #")                             ("
0 0 14 3 10 #"token-LOAD"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 8 #"\"NUMBER\""
0 0 24 3 1 #" "
0 0 19 3 8 #"\"Number\""
0 0 24 3 27 #")                         ("
0 0 14 3 12 #"token-NUMBER"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 7 #"\"VALUE\""
0 0 24 3 2 #"  "
0 0 19 3 7 #"\"Value\""
0 0 24 3 28 #")                          ("
0 0 14 3 11 #"token-VALUE"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 5 #"\"KEY\""
0 0 24 3 1 #" "
0 0 19 3 5 #"\"Key\""
0 0 24 3 33 #")                               ("
0 0 14 3 9 #"token-KEY"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 5 #"\"NET\""
0 0 24 3 1 #" "
0 0 19 3 5 #"\"Net\""
0 0 24 3 33 #")                               ("
0 0 14 3 9 #"token-NET"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 6 #"\"TIME\""
0 0 24 3 1 #" "
0 0 19 3 6 #"\"Time\""
0 0 24 3 31 #")                             ("
0 0 14 3 10 #"token-TIME"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 7 #"\"PRINT\""
0 0 24 3 1 #" "
0 0 19 3 7 #"\"Print\""
0 0 24 3 29 #")                           ("
0 0 14 3 11 #"token-PRINT"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 9 #"\"COMMAND\""
0 0 24 3 1 #" "
0 0 19 3 9 #"\"Command\""
0 0 24 3 25 #")                       ("
0 0 14 3 13 #"token-COMMAND"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 8 #"\"NUMBER\""
0 0 24 3 1 #" "
0 0 19 3 8 #"\"Number\""
0 0 24 3 27 #")                         ("
0 0 14 3 12 #"token-NUMBER"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 11 #"\"ANTIALIAS\""
0 0 24 3 1 #" "
0 0 19 3 11 #"\"Antialias\""
0 0 24 3 21 #")                   ("
0 0 14 3 15 #"token-ANTIALIAS"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 49 #";;; Step 1: Added Paper, Pen, Line, Set to lexer "
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 5 #"\"Pen\""
0 0 24 3 1 #" "
0 0 19 3 5 #"\"pen\""
0 0 24 3 1 #" "
0 0 19 3 5 #"\"PEN\""
0 0 24 3 27 #")                         ("
0 0 14 3 9 #"token-PEN"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 7 #"\"Paper\""
0 0 24 3 1 #" "
0 0 19 3 7 #"\"paper\""
0 0 24 3 1 #" "
0 0 19 3 7 #"\"PAPER\""
0 0 24 3 21 #")                   ("
0 0 14 3 11 #"token-PAPER"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 6 #"\"Line\""
0 0 24 3 1 #" "
0 0 19 3 6 #"\"line\""
0 0 24 3 1 #" "
0 0 19 3 6 #"\"LINE\""
0 0 24 3 24 #")                      ("
0 0 14 3 10 #"token-LINE"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 19 3 5 #"\"Set\""
0 0 24 3 1 #" "
0 0 19 3 4 #"\"SET"
0 0 19 3 1 #"\""
0 0 24 3 1 #" "
0 0 19 3 4 #"\"set"
0 0 19 3 1 #"\""
0 0 24 3 27 #")                         ("
0 0 14 3 9 #"token-SET"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 40 #";;; Step 2: Add identifiers and numbers "
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 13 #"; identifiers"
0 0 24 29 1 #"\n"
0 0 24 3 6 #"    [("
0 0 14 3 2 #"::"
0 0 24 3 1 #" "
0 0 14 3 10 #"alphabetic"
0 0 24 3 2 #" ("
0 0 14 3 2 #":*"
0 0 24 3 2 #" ("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 14 3 10 #"alphabetic"
0 0 24 3 1 #" "
0 0 14 3 7 #"numeric"
0 0 24 3 7 #")))   ("
0 0 14 3 16 #"token-IDENTIFIER"
0 0 24 3 1 #" "
0 0 14 3 6 #"lexeme"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 9 #"; numbers"
0 0 24 29 1 #"\n"
0 0 24 3 6 #"    [("
0 0 14 3 2 #":+"
0 0 24 3 1 #" "
0 0 14 3 7 #"numeric"
0 0 24 3 36 #")                                  ("
0 0 14 3 18 #"token-NUMERICVALUE"
0 0 24 3 2 #" ("
0 0 14 3 14 #"string->number"
0 0 24 3 1 #" "
0 0 14 3 6 #"lexeme"
0 0 24 3 3 #"))]"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"    "
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 10 #"; comments"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 2 #"::"
0 0 24 3 1 #" "
0 0 19 3 1 #"\""
0 0 19 3 3 #"//\""
0 0 24 3 2 #" ("
0 0 14 3 2 #":*"
0 0 24 3 2 #" ("
0 0 14 3 15 #"char-complement"
0 0 24 3 2 #" ("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 21 3 9 #"#\\newline"
0 0 24 3 1 #" "
0 0 21 3 10 #"#\\linefeed"
0 0 24 3 3 #")))"
0 0 24 29 1 #"\n"
0 0 24 3 9 #"        ("
0 0 14 3 2 #":+"
0 0 24 3 2 #" ("
0 0 14 3 3 #":or"
0 0 24 3 1 #" "
0 0 21 3 9 #"#\\newline"
0 0 24 3 1 #" "
0 0 21 3 10 #"#\\linefeed"
0 0 24 3 5 #"))) ("
0 0 14 3 18 #"return-without-pos"
0 0 24 3 2 #" ("
0 0 14 3 8 #"dbnlexer"
0 0 24 3 1 #" "
0 0 14 3 10 #"input-port"
0 0 24 3 3 #"))]"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 36 #"; handle a lang line so we ignore it"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 2 #"::"
0 0 24 3 1 #" "
0 0 19 3 7 #"\"#lang\""
0 0 24 3 2 #" ("
0 0 14 3 2 #":+"
0 0 24 3 2 #" ("
0 0 14 3 5 #"union"
0 0 24 3 1 #" "
0 0 21 3 7 #"#\\space"
0 0 24 3 1 #" "
0 0 21 3 5 #"#\\tab"
0 0 24 3 4 #")) ("
0 0 14 3 5 #"union"
0 0 24 3 1 #" "
0 0 19 3 4 #"\"dbn"
0 0 19 3 1 #"\""
0 0 24 3 1 #" "
0 0 19 3 9 #"\"dbn-lang"
0 0 19 3 1 #"\""
0 0 24 3 4 #")) ("
0 0 14 3 18 #"return-without-pos"
0 0 24 3 2 #" ("
0 0 14 3 8 #"dbnlexer"
0 0 24 3 1 #" "
0 0 14 3 10 #"input-port"
0 0 24 3 3 #"))]"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 19 #"; ignore whitespace"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 14 3 10 #"whitespace"
0 0 24 3 2 #" ("
0 0 14 3 18 #"return-without-pos"
0 0 24 3 2 #" ("
0 0 14 3 8 #"dbnlexer"
0 0 24 3 1 #" "
0 0 14 3 10 #"input-port"
0 0 24 3 3 #"))]"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 15 #"; good, ole eof"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"   [("
0 0 14 3 3 #"eof"
0 0 24 3 3 #") ("
0 0 14 3 9 #"token-EOF"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"   "
0 0 17 3 55 #"; anything else is a syntax error, so report it as such"
0 0 24 29 1 #"\n"
0 0 24 3 4 #"   ["
0 0 14 3 8 #"any-char"
0 0 24 3 2 #" ("
0 0 14 3 15 #"raise-lex-error"
0 0 24 3 1 #" "
0 0 14 3 9 #"start-pos"
0 0 24 3 1 #" "
0 0 14 3 6 #"lexeme"
0 0 24 3 4 #")]))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 29 #"; position -> string -> error"
0 0 24 29 1 #"\n"
0 0 17 3 23 #"; raises a lexing error"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 2 #" ("
0 0 14 3 15 #"raise-lex-error"
0 0 24 3 1 #" "
0 0 14 3 3 #"pos"
0 0 24 3 1 #" "
0 0 14 3 6 #"lexeme"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 15 3 4 #"let*"
0 0 24 3 3 #" (["
0 0 14 3 9 #"linenums?"
0 0 24 3 2 #" ("
0 0 14 3 3 #"not"
0 0 24 3 2 #" ("
0 0 14 3 3 #"eq?"
0 0 24 3 2 #" ("
0 0 14 3 13 #"position-line"
0 0 24 3 1 #" "
0 0 14 3 3 #"pos"
0 0 24 3 2 #") "
0 0 21 3 2 #"#f"
0 0 24 3 3 #"))]"
0 0 24 29 1 #"\n"
0 0 24 3 10 #"         ["
0 0 14 3 3 #"loc"
0 0 24 3 2 #" ("
0 0 14 3 2 #"if"
0 0 24 3 1 #" "
0 0 14 3 9 #"linenums?"
0 0 24 3 2 #" ("
0 0 14 3 13 #"position-line"
0 0 24 3 1 #" "
0 0 14 3 3 #"pos"
0 0 24 3 3 #") ("
0 0 14 3 15 #"position-offset"
0 0 24 3 1 #" "
0 0 14 3 3 #"pos"
0 0 24 3 3 #"))]"
0 0 24 29 1 #"\n"
0 0 24 3 10 #"         ["
0 0 14 3 3 #"col"
0 0 24 3 2 #" ("
0 0 14 3 12 #"position-col"
0 0 24 3 1 #" "
0 0 14 3 3 #"pos"
0 0 24 3 2 #")]"
0 0 24 29 1 #"\n"
0 0 24 3 10 #"         ["
0 0 14 3 11 #"partial-msg"
0 0 24 3 2 #" ("
0 0 14 3 13 #"string-append"
0 0 24 3 2 #" ("
0 0 14 3 2 #"if"
0 0 24 3 1 #" "
0 0 14 3 9 #"linenums?"
0 0 24 3 1 #" "
0 0 19 3 1 #"\""
0 0 19 3 6 #"syntax"
0 0 19 3 1 #" "
0 0 19 3 5 #"error"
0 0 19 3 1 #" "
0 0 19 3 2 #"at"
0 0 19 3 1 #" "
0 0 19 3 5 #"line "
0 0 19 3 1 #"\""
0 0 24 29 1 #"\n"
0 0 24 3 41 #"                                         "
0 0 19 3 1 #"\""
0 0 19 3 6 #"syntax"
0 0 19 3 1 #" "
0 0 19 3 5 #"error"
0 0 19 3 1 #" "
0 0 19 3 2 #"at"
0 0 19 3 1 #" "
0 0 19 3 7 #"offset "
0 0 19 3 1 #"\""
0 0 24 3 3 #") ("
0 0 14 3 14 #"number->string"
0 0 24 3 1 #" "
0 0 14 3 3 #"loc"
0 0 24 3 3 #"))]"
0 0 24 29 1 #"\n"
0 0 24 3 10 #"         ["
0 0 14 3 3 #"msg"
0 0 24 3 2 #" ("
0 0 14 3 13 #"string-append"
0 0 24 3 1 #" "
0 0 14 3 11 #"partial-msg"
0 0 24 3 2 #" ("
0 0 14 3 2 #"if"
0 0 24 3 1 #" "
0 0 14 3 9 #"linenums?"
0 0 24 3 2 #" ("
0 0 14 3 13 #"string-append"
0 0 24 3 1 #" "
0 0 19 3 1 #"\""
0 0 19 3 1 #","
0 0 19 3 1 #" "
0 0 19 3 4 #"col "
0 0 19 3 1 #"\""
0 0 24 3 2 #" ("
0 0 14 3 14 #"number->string"
0 0 24 3 1 #" "
0 0 14 3 3 #"col"
0 0 24 3 3 #")) "
0 0 19 3 2 #"\"\""
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 29 #"                             "
0 0 19 3 1 #"\""
0 0 19 3 1 #":"
0 0 19 3 2 #" '"
0 0 19 3 1 #"\""
0 0 24 3 1 #" "
0 0 14 3 6 #"lexeme"
0 0 24 3 1 #" "
0 0 19 3 1 #"\""
0 0 19 3 2 #"'\""
0 0 24 3 3 #")])"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"    ("
0 0 14 3 11 #"lexer-error"
0 0 24 3 1 #" "
0 0 21 3 2 #"#t"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"    ("
0 0 14 3 18 #"raise-syntax-error"
0 0 24 3 1 #" "
0 0 21 3 1 #"'"
0 0 14 3 8 #"dbnlexer"
0 0 24 3 1 #" "
0 0 14 3 3 #"msg"
0 0 24 3 3 #")))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 21 #"; input port -> thunk"
0 0 24 29 1 #"\n"
0 0 17 3 83
(
 #"; creates a thunk that when called will return the next token from t"
 #"he input stream"
) 0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 2 #" ("
0 0 14 3 13 #"get-tokenizer"
0 0 24 3 1 #" "
0 0 14 3 2 #"in"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 15 3 2 #"\316\273"
0 0 24 3 5 #" () ("
0 0 14 3 8 #"dbnlexer"
0 0 24 3 1 #" "
0 0 14 3 2 #"in"
0 0 24 3 3 #")))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 30 #"; input port -> list of tokens"
0 0 24 29 1 #"\n"
0 0 17 3 57 #"; this function takes an input port and returns a list of"
0 0 24 29 1 #"\n"
0 0 17 3 41 #"; tokens read from it (until it hits eof)"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 2 #" ("
0 0 14 3 3 #"lex"
0 0 24 3 1 #" "
0 0 14 3 2 #"in"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 14 3 17 #"port-count-lines!"
0 0 24 3 1 #" "
0 0 14 3 2 #"in"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 15 3 3 #"let"
0 0 24 3 3 #" (["
0 0 14 3 8 #"tokenize"
0 0 24 3 2 #" ("
0 0 14 3 13 #"get-tokenizer"
0 0 24 3 1 #" "
0 0 14 3 2 #"in"
0 0 24 3 3 #")])"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"    ("
0 0 15 3 6 #"define"
0 0 24 3 2 #" ("
0 0 14 3 6 #"lexfun"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 7 #"      ("
0 0 15 3 3 #"let"
0 0 24 3 3 #" (["
0 0 14 3 3 #"tok"
0 0 24 3 2 #" ("
0 0 14 3 8 #"tokenize"
0 0 24 3 3 #")])"
0 0 24 29 1 #"\n"
0 0 24 3 9 #"        ("
0 0 15 3 4 #"cond"
0 0 24 29 1 #"\n"
0 0 24 3 10 #"          "
0 0 17 3 44 #"; test to see if we hit eof as the base case"
0 0 24 29 1 #"\n"
0 0 24 3 12 #"          [("
0 0 14 3 3 #"eq?"
0 0 24 3 2 #" ("
0 0 14 3 20 #"position-token-token"
0 0 24 3 1 #" "
0 0 14 3 3 #"tok"
0 0 24 3 3 #") ("
0 0 14 3 9 #"token-EOF"
0 0 24 3 3 #")) "
0 0 14 3 4 #"null"
0 0 24 3 1 #"]"
0 0 24 29 1 #"\n"
0 0 24 3 11 #"          ["
0 0 14 3 4 #"else"
0 0 24 3 2 #" ("
0 0 14 3 4 #"cons"
0 0 24 3 2 #" ("
0 0 14 3 20 #"position-token-token"
0 0 24 3 1 #" "
0 0 14 3 3 #"tok"
0 0 24 3 3 #") ("
0 0 14 3 6 #"lexfun"
0 0 24 3 6 #"))])))"
0 0 24 29 1 #"\n"
0 0 24 3 5 #"    ("
0 0 14 3 6 #"lexfun"
0 0 24 3 3 #")))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 26 #"; string -> list of tokens"
0 0 24 29 1 #"\n"
0 0 17 3 52 #"; this function takes a string and returns a list of"
0 0 24 29 1 #"\n"
0 0 17 3 48 #"; tokens read from it (until it reaches the end)"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 2 #" ("
0 0 14 3 7 #"lex-str"
0 0 24 3 1 #" "
0 0 14 3 3 #"str"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 14 3 3 #"lex"
0 0 24 3 2 #" ("
0 0 14 3 17 #"open-input-string"
0 0 24 3 1 #" "
0 0 14 3 3 #"str"
0 0 24 3 3 #")))"
0 0 24 29 1 #"\n"
0 0 24 29 1 #"\n"
0 0 17 3 28 #"; filename -> list of tokens"
0 0 24 29 1 #"\n"
0 0 17 3 60
#"; this function takes a filename, opens it as an input port,"
0 0 24 29 1 #"\n"
0 0 17 3 48 #"; and then reads tokens until the end is reached"
0 0 24 29 1 #"\n"
0 0 24 3 1 #"("
0 0 15 3 6 #"define"
0 0 24 3 2 #" ("
0 0 14 3 8 #"lex-file"
0 0 24 3 1 #" "
0 0 14 3 8 #"filename"
0 0 24 3 1 #")"
0 0 24 29 1 #"\n"
0 0 24 3 3 #"  ("
0 0 14 3 3 #"lex"
0 0 24 3 2 #" ("
0 0 14 3 15 #"open-input-file"
0 0 24 3 1 #" "
0 0 14 3 8 #"filename"
0 0 24 3 3 #")))"
0 0 24 29 1 #"\n"
0           0
